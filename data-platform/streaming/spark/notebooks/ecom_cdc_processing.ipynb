{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11c249e6-f835-4fb3-be63-1d08bf7355e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://64f1e14fd5a7:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Ecommerce CDC Processing</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f765e673100>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the Spark Session\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = (\n",
    "    SparkSession \n",
    "    .builder \n",
    "    .appName(\"Ecommerce CDC Processing\") \n",
    "    .config(\"spark.streaming.stopGracefullyOnShutdown\", True) \n",
    "    .config(\n",
    "        'spark.jars.packages',\n",
    "        'org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.0'\n",
    "    )\n",
    "    .config(\"spark.sql.shuffle.partitions\", 8)\n",
    "    .master(\"local[*]\") \n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44652886-b8f5-4d24-80ba-5d3fca1ad5d6",
   "metadata": {},
   "source": [
    "## Connect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfab10ec-702b-4a1c-be72-542551c4492b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”— Kafka servers: kafka1:9092\n",
      "ðŸ“‹ CDC topic: pg.public.customers\n",
      "âœ… Kafka stream is connected\n",
      "root\n",
      " |-- key: binary (nullable = true)\n",
      " |-- value: binary (nullable = true)\n",
      " |-- topic: string (nullable = true)\n",
      " |-- partition: integer (nullable = true)\n",
      " |-- offset: long (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- timestampType: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- Connect to Kafka ---\n",
    "KAFKA_SERVERS = \"kafka1:9092\"\n",
    "CDC_TOPIC = \"pg.public.customers\"\n",
    "\n",
    "print(f\"ðŸ”— Kafka servers: {KAFKA_SERVERS}\")\n",
    "print(f\"ðŸ“‹ CDC topic: {CDC_TOPIC}\")\n",
    "\n",
    "kafka_stream = (\n",
    "    spark.read\n",
    "    .format(\"kafka\")\n",
    "    .option(\"kafka.bootstrap.servers\", KAFKA_SERVERS)\n",
    "    .option(\"subscribe\", CDC_TOPIC)\n",
    "    # .option(\"startingOffsets\", \"latest\")\n",
    "    .load()\n",
    ")\n",
    "\n",
    "print(\"âœ… Kafka stream is connected\")\n",
    "kafka_stream.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c91e85d0-8d1a-4f74-93e5-b411cd0e1371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-------------------+---------+------+--------------------+-------------+\n",
      "|                 key|               value|              topic|partition|offset|           timestamp|timestampType|\n",
      "+--------------------+--------------------+-------------------+---------+------+--------------------+-------------+\n",
      "|[7B 22 69 64 22 3...|[7B 22 62 65 66 6...|pg.public.customers|        0|     0|2025-08-09 12:22:...|            0|\n",
      "|[7B 22 69 64 22 3...|[7B 22 62 65 66 6...|pg.public.customers|        0|     1|2025-08-09 12:22:...|            0|\n",
      "+--------------------+--------------------+-------------------+---------+------+--------------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kafka_stream.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9202d578-9b16-44af-bc80-4ba191c7cc7a",
   "metadata": {},
   "source": [
    "## Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86ab841-8929-4695-969f-ac897e519b64",
   "metadata": {},
   "source": [
    "### Parse raw message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0581d154-e528-4e68-917f-843fedaf42fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "# Define UDF to decode byte array to string\n",
    "def decode_bytes(bytes_array):\n",
    "    if bytes_array is not None:\n",
    "        try:\n",
    "            # Convert byte array to Python bytes and decode as UTF-8\n",
    "            return bytes(bytes_array).decode('utf-8')\n",
    "        except Exception:\n",
    "            return None\n",
    "    return None\n",
    "decode_udf = udf(decode_bytes, StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ef562bb-c9ef-4e0e-9d05-ca273a1d9ed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-------------------+---------+------+--------------------+-------------+--------+--------------------+\n",
      "|                 key|               value|              topic|partition|offset|           timestamp|timestampType| key_str|           value_str|\n",
      "+--------------------+--------------------+-------------------+---------+------+--------------------+-------------+--------+--------------------+\n",
      "|[7B 22 69 64 22 3...|[7B 22 62 65 66 6...|pg.public.customers|        0|     0|2025-08-09 12:22:...|            0|{\"id\":1}|{\"before\":null,\"a...|\n",
      "|[7B 22 69 64 22 3...|[7B 22 62 65 66 6...|pg.public.customers|        0|     1|2025-08-09 12:22:...|            0|{\"id\":2}|{\"before\":null,\"a...|\n",
      "+--------------------+--------------------+-------------------+---------+------+--------------------+-------------+--------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import expr, col\n",
    "\n",
    "# --- Parse binary raw message ---\n",
    "kafka_json_df = (\n",
    "     kafka_stream\n",
    "    .withColumn('key_str', decode_udf(col(\"key\")))\n",
    "    .withColumn('value_str', expr('cast(value as string)'))\n",
    ")\n",
    "\n",
    "kafka_json_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43255d98-efdd-4858-a076-5b7c37db6cbc",
   "metadata": {},
   "source": [
    "### Extract JSON data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6d709c4b-51bc-48a5-94f8-943b2b9b27fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, IntegerType, StringType, LongType, StructField\n",
    "\n",
    "# Schema for CDC value JSON (Debezium format)\n",
    "key_schema = StructType([\n",
    "    StructField(\"id\", IntegerType(), True)\n",
    "])\n",
    "\n",
    "value_schema = StructType([\n",
    "    StructField(\"before\", StructType([\n",
    "        StructField(\"id\", IntegerType(), True),\n",
    "        StructField(\"name\", StringType(), True),\n",
    "        StructField(\"email\", StringType(), True),\n",
    "        StructField(\"created_at\", LongType(), True)\n",
    "    ]), True),\n",
    "    StructField(\"after\", StructType([\n",
    "        StructField(\"id\", IntegerType(), True),\n",
    "        StructField(\"name\", StringType(), True),\n",
    "        StructField(\"email\", StringType(), True),\n",
    "        StructField(\"created_at\", LongType(), True)\n",
    "    ]), True),\n",
    "    StructField(\"source\", StructType([\n",
    "        StructField(\"ts_ms\", LongType(), True),\n",
    "        StructField(\"schema\", StringType(), True),\n",
    "        StructField(\"table\", StringType(), True)\n",
    "    ]), True),\n",
    "    StructField(\"op\", StringType(), True),\n",
    "    StructField(\"ts_ms\", LongType(), True)  # Transaction timestamp\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e5437c51-83ae-47a8-a683-450e275ba07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import from_json\n",
    "\n",
    "transformed_df = (\n",
    "    kafka_json_df\n",
    "    .withColumn(\"key_json\", from_json(col(\"key_str\"), key_schema))\n",
    "    .withColumn('value_json', from_json(col('value_str'), value_schema))\n",
    "    .drop('value', 'key')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bd630629-9d6d-41ce-9b1e-b9f6be4e4f8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------+------+--------------------+-------------+---------+--------------------+--------+--------------------+\n",
      "|              topic|partition|offset|           timestamp|timestampType|  key_str|           value_str|key_json|          value_json|\n",
      "+-------------------+---------+------+--------------------+-------------+---------+--------------------+--------+--------------------+\n",
      "|pg.public.customers|        0|     0|2025-08-09 12:22:...|            0| {\"id\":1}|{\"before\":null,\"a...|     {1}|{null, {1, Alice,...|\n",
      "|pg.public.customers|        0|     1|2025-08-09 12:22:...|            0| {\"id\":2}|{\"before\":null,\"a...|     {2}|{null, {2, Bob, b...|\n",
      "|pg.public.customers|        0|     2|2025-08-10 05:40:...|            0| {\"id\":3}|{\"before\":null,\"a...|     {3}|{null, {3, BatchC...|\n",
      "|pg.public.customers|        0|     3|2025-08-10 05:40:...|            0| {\"id\":4}|{\"before\":null,\"a...|     {4}|{null, {4, BatchC...|\n",
      "|pg.public.customers|        0|     4|2025-08-10 05:40:...|            0| {\"id\":5}|{\"before\":null,\"a...|     {5}|{null, {5, BatchC...|\n",
      "|pg.public.customers|        0|     5|2025-08-10 05:40:...|            0| {\"id\":6}|{\"before\":null,\"a...|     {6}|{null, {6, BatchC...|\n",
      "|pg.public.customers|        0|     6|2025-08-10 05:40:...|            0| {\"id\":7}|{\"before\":null,\"a...|     {7}|{null, {7, BatchC...|\n",
      "|pg.public.customers|        0|     7|2025-08-10 05:40:...|            0| {\"id\":8}|{\"before\":null,\"a...|     {8}|{null, {8, BatchC...|\n",
      "|pg.public.customers|        0|     8|2025-08-10 05:40:...|            0| {\"id\":9}|{\"before\":null,\"a...|     {9}|{null, {9, BatchC...|\n",
      "|pg.public.customers|        0|     9|2025-08-10 05:40:...|            0|{\"id\":10}|{\"before\":null,\"a...|    {10}|{null, {10, Batch...|\n",
      "|pg.public.customers|        0|    10|2025-08-10 05:40:...|            0|{\"id\":11}|{\"before\":null,\"a...|    {11}|{null, {11, Batch...|\n",
      "|pg.public.customers|        0|    11|2025-08-10 05:40:...|            0|{\"id\":12}|{\"before\":null,\"a...|    {12}|{null, {12, Batch...|\n",
      "|pg.public.customers|        0|    12|2025-08-10 05:41:...|            0| {\"id\":3}|{\"before\":{\"id\":3...|     {3}|{{3, BatchCustome...|\n",
      "|pg.public.customers|        0|    13|2025-08-10 05:41:...|            0| {\"id\":1}|{\"before\":{\"id\":1...|     {1}|{{1, Alice, alice...|\n",
      "+-------------------+---------+------+--------------------+-------------+---------+--------------------+--------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transformed_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b5e91e-acaa-4684-9c6d-bf07da34ec28",
   "metadata": {},
   "source": [
    "### Handle CDC ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9a86842b-519b-4049-9c68-000ddb1190b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+--------------------+----------------+-------------+--------+\n",
      "| id|                name|               email|      created_at|     _version|_deleted|\n",
      "+---+--------------------+--------------------+----------------+-------------+--------+\n",
      "|  1|               Alice|   alice@example.com|1754742098873040|1754742168187|       0|\n",
      "|  2|                 Bob|     bob@example.com|1754742098873040|1754742168196|       0|\n",
      "|  3|BatchCustomer_175...|batchcustomer_175...|1754803956937329|1754804426754|       0|\n",
      "|  4|BatchCustomer_175...|batchcustomer_175...|1754804426378610|1754804426782|       0|\n",
      "|  5|BatchCustomer_175...|batchcustomer_175...|1754804426381457|1754804426784|       0|\n",
      "|  6|BatchCustomer_175...|batchcustomer_175...|1754804426383958|1754804426785|       0|\n",
      "|  7|BatchCustomer_175...|batchcustomer_175...|1754804426386369|1754804426786|       0|\n",
      "|  8|BatchCustomer_175...|batchcustomer_175...|1754804426389480|1754804426786|       0|\n",
      "|  9|BatchCustomer_175...|batchcustomer_175...|1754804426393612|1754804426787|       0|\n",
      "| 10|BatchCustomer_175...|batchcustomer_175...|1754804426396510|1754804426788|       0|\n",
      "| 11|BatchCustomer_175...|batchcustomer_175...|1754804426398986|1754804426789|       0|\n",
      "| 12|BatchCustomer_175...|batchcustomer_175...|1754804426401162|1754804426790|       0|\n",
      "|  3|BatchCustomer_175...|batchcustomer_175...|1754803956937329|1754804480962|       0|\n",
      "|  1|               Alice|  alice1@example.com|1754742098873040|1754804485012|       0|\n",
      "|  3|editnameBatchCust...|batchcustomer_175...|1754803956937329|1754804718858|       0|\n",
      "|  3|                null|                null|            null|1754804725944|       1|\n",
      "|  3|                null|                null|            null|         null|       0|\n",
      "+---+--------------------+--------------------+----------------+-------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import when, lit\n",
    "\n",
    "# --- Extract fields & handle CDC ops\n",
    "# For create/update/read: Use 'after' + _version = ts_ms\n",
    "# For delete: Insert with null fields or skip (for ReplacingMergeTree, insert with higher _version to replace)\n",
    "cdc_df = transformed_df.select(\n",
    "    # ID: From after/before/key\n",
    "    when(col(\"value_json.op\").isin(\"c\", \"u\", \"r\"), col(\"value_json.after.id\"))\n",
    "    .when(col(\"value_json.op\") == \"d\", col(\"value_json.before.id\"))\n",
    "    .otherwise(col(\"key_json.id\")).alias(\"id\"),\n",
    "    \n",
    "    # Fields: From after for insert/update, null for delete\n",
    "    when(col(\"value_json.op\").isin(\"c\", \"u\", \"r\"), col(\"value_json.after.name\"))\n",
    "    .otherwise(lit(None)).alias(\"name\"),\n",
    "    \n",
    "    when(col(\"value_json.op\").isin(\"c\", \"u\", \"r\"), col(\"value_json.after.email\"))\n",
    "    .otherwise(lit(None)).alias(\"email\"),\n",
    "    \n",
    "    when(col(\"value_json.op\").isin(\"c\", \"u\", \"r\"), col(\"value_json.after.created_at\"))\n",
    "    .otherwise(lit(None)).alias(\"created_at\"),\n",
    "    \n",
    "    # _version: From ts_ms\n",
    "    col(\"value_json.ts_ms\").alias(\"_version\"),\n",
    "    \n",
    "    # _deleted: 0 for insert/update, 1 for delete\n",
    "    when(col(\"value_json.op\") == \"d\", lit(1))\n",
    "    .otherwise(lit(0)).alias(\"_deleted\")\n",
    ")\n",
    "\n",
    "cdc_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cfbf321-c72f-4489-86e4-866734e6ec5b",
   "metadata": {},
   "source": [
    "## Write event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f433ad-5f0e-4f90-9e38-ffc545fa0ca1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
