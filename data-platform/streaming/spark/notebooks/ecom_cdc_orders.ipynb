{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72a75b6a-ee6a-4acf-bdd6-fd0560c00bd9",
   "metadata": {},
   "source": [
    "## Load config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a08ba9e-bfb8-4f85-ab28-de879e47dce1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/jupyter/src-streaming/spark')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "project_root = Path().absolute().parent\n",
    "project_root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1e000c3-aa0b-47d2-8f1a-d1cacc369983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: /home/jupyter/src-streaming/spark\n",
      "Src path: /home/jupyter/src-streaming/spark/src\n",
      "Src path exists: True\n"
     ]
    }
   ],
   "source": [
    "# Add src directory to Python path\n",
    "src_path = project_root / \"src\"\n",
    "sys.path.insert(0, str(src_path))\n",
    "\n",
    "print(f\"Project root: {project_root}\")\n",
    "print(f\"Src path: {src_path}\")\n",
    "print(f\"Src path exists: {src_path.exists()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a253eff-9c27-4e8e-9e7a-58f8bf9acd68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparkConfig(app_name='Ecommerce CDC Processing', master='local[*]', shuffle_partitions=8, packages='org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.0,com.clickhouse:clickhouse-jdbc:0.6.0')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from config.app_config import AppConfig\n",
    "\n",
    "app_config = AppConfig()\n",
    "app_config.spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "297b62f2-4ea6-45e3-a8ad-6808a9c691ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'spark.streaming.stopGracefullyOnShutdown': True,\n",
       " 'spark.jars.packages': 'org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.0,com.clickhouse:clickhouse-jdbc:0.6.0',\n",
       " 'spark.sql.shuffle.partitions': 8}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark_configs = app_config.spark.get_spark_configs()\n",
    "spark_configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d5f6a7e-a5bb-44db-a4ce-8fdf68fac3a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://38d347f28773:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Ecommerce CDC Processing (products)</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f016347e9b0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the Spark Session\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "builder = SparkSession.builder.appName(f'{app_config.spark.app_name} (products)')\n",
    "\n",
    "for key, value in app_config.spark.get_spark_configs().items():\n",
    "    builder = builder.config(key, value)\n",
    "\n",
    "builder = builder.master(app_config.spark.master)\n",
    "spark = builder.getOrCreate()\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9ce85a-4323-4874-a5fd-140022ce5104",
   "metadata": {},
   "source": [
    "## Read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51561b9a-384f-4d3c-b1a3-79a1762335f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KafkaConfig(bootstrap_servers='kafka1:9092', topics={'customers': 'pg.public.customers', 'orders': 'pg.public.orders', 'products': 'pg.public.products'})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'pg.public.orders'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(app_config.kafka)\n",
    "\n",
    "app_config.kafka.topics.get('orders')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35855a9f-e470-43e2-aa7a-43a1382aaf86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- key: binary (nullable = true)\n",
      " |-- value: binary (nullable = true)\n",
      " |-- topic: string (nullable = true)\n",
      " |-- partition: integer (nullable = true)\n",
      " |-- offset: long (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- timestampType: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kafka_stream = (\n",
    "    spark\n",
    "    .read\n",
    "    .format('kafka')\n",
    "    .option(\"kafka.bootstrap.servers\", app_config.kafka.bootstrap_servers)\n",
    "    .option(\"subscribe\", app_config.kafka.topics.get('orders'))\n",
    "    # .option(\"startingOffsets\", \"latest\")\n",
    "    .load()\n",
    ")\n",
    "\n",
    "kafka_stream.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c40ced3-4821-4b2d-98a0-eb66b6a4f956",
   "metadata": {},
   "source": [
    "### Apply schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9596905-68b3-4503-9eac-6afb7f5b0fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import expr, col\n",
    "from utils.helpers import decode_udf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe205081-edbe-4756-beaa-f860f4299159",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Parse binary raw message ---\n",
    "kafka_json_df = (\n",
    "    kafka_stream\n",
    "    .withColumn('key_str', expr('cast(key as string)'))\n",
    "    .withColumn('value_str', expr('cast(value as string)'))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16efa832-0067-4a99-897f-a4265029c8c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+----------------+---------+------+--------------------+-------------+--------+--------------------+\n",
      "|                 key|               value|           topic|partition|offset|           timestamp|timestampType| key_str|           value_str|\n",
      "+--------------------+--------------------+----------------+---------+------+--------------------+-------------+--------+--------------------+\n",
      "|[7B 22 69 64 22 3...|[7B 22 62 65 66 6...|pg.public.orders|        0|     0|2025-08-19 08:57:...|            0|{\"id\":1}|{\"before\":null,\"a...|\n",
      "|[7B 22 69 64 22 3...|[7B 22 62 65 66 6...|pg.public.orders|        0|     1|2025-08-19 08:57:...|            0|{\"id\":2}|{\"before\":null,\"a...|\n",
      "|[7B 22 69 64 22 3...|[7B 22 62 65 66 6...|pg.public.orders|        0|     2|2025-08-19 08:57:...|            0|{\"id\":3}|{\"before\":null,\"a...|\n",
      "+--------------------+--------------------+----------------+---------+------+--------------------+-------------+--------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kafka_json_df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d995903-e53b-4353-9743-e86ddfe377ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, IntegerType, StringType, LongType, StructField\n",
    "\n",
    "# Schema for CDC value JSON (Debezium format)\n",
    "key_schema = StructType([\n",
    "    StructField(\"id\", IntegerType(), True)\n",
    "])\n",
    "\n",
    "\n",
    "order_record_schema = StructType([\n",
    "            StructField(\"id\", IntegerType(), True),\n",
    "            StructField(\"customer_id\", IntegerType(), True),\n",
    "            StructField(\"product_id\", IntegerType(), True),\n",
    "            StructField(\"quantity\", IntegerType(), True),\n",
    "            StructField(\"order_time\", LongType(), True)\n",
    "        ])\n",
    "        \n",
    "\n",
    "value_schema =  StructType([\n",
    "            StructField(\"before\", order_record_schema, True),\n",
    "            StructField(\"after\", order_record_schema, True),\n",
    "            StructField(\"source\", StructType([\n",
    "                StructField(\"ts_ms\", LongType(), True),\n",
    "                StructField(\"schema\", StringType(), True),\n",
    "                StructField(\"table\", StringType(), True)\n",
    "            ]), True),\n",
    "            StructField(\"op\", StringType(), True),\n",
    "            StructField(\"ts_ms\", LongType(), True)\n",
    "        ])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "695aa781-ec2f-4b61-9dcf-91d307f21d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import from_json\n",
    "\n",
    "transformed_df = (\n",
    "    kafka_json_df\n",
    "    .withColumn(\"key_json\", from_json(col(\"key_str\"), key_schema))\n",
    "    .withColumn('value_json', from_json(col('value_str'), value_schema))\n",
    "    .drop('value', 'key')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2eefecf2-0c87-4b57-8163-927cf1ff4725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+---------+------+--------------------+-------------+--------+--------------------+--------+--------------------+\n",
      "|           topic|partition|offset|           timestamp|timestampType| key_str|           value_str|key_json|          value_json|\n",
      "+----------------+---------+------+--------------------+-------------+--------+--------------------+--------+--------------------+\n",
      "|pg.public.orders|        0|     0|2025-08-19 08:57:...|            0|{\"id\":1}|{\"before\":null,\"a...|     {1}|{null, {1, 5, 77,...|\n",
      "|pg.public.orders|        0|     1|2025-08-19 08:57:...|            0|{\"id\":2}|{\"before\":null,\"a...|     {2}|{null, {2, 5, 31,...|\n",
      "+----------------+---------+------+--------------------+-------------+--------+--------------------+--------+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transformed_df.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47580688-a939-4614-88a4-b1de1b6d71e1",
   "metadata": {},
   "source": [
    "### Handle CDC ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "16f7ee4d-53f5-4459-9e1e-12f68f471309",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when, lit\n",
    "\n",
    "# --- Extract fields & handle CDC ops\n",
    "# For create/update/read: Use 'after' + _version = ts_ms\n",
    "# For delete: Insert with null fields or skip (for ReplacingMergeTree, insert with higher _version to replace)\n",
    "cdc_df = transformed_df.select(\n",
    "            # ID: after/before/key\n",
    "            when(col(\"value_json.op\").isin(\"c\", \"u\", \"r\"), col(\"value_json.after.id\"))\n",
    "              .when(col(\"value_json.op\") == \"d\", col(\"value_json.before.id\"))\n",
    "              .otherwise(col(\"key_json.id\")).alias(\"id\"),\n",
    "\n",
    "            # Fields\n",
    "            when(col(\"value_json.op\").isin(\"c\", \"u\", \"r\"), col(\"value_json.after.customer_id\"))\n",
    "              .otherwise(lit(None)).alias(\"customer_id\"),\n",
    "\n",
    "            when(col(\"value_json.op\").isin(\"c\", \"u\", \"r\"), col(\"value_json.after.product_id\"))\n",
    "              .otherwise(lit(None)).alias(\"product_id\"),\n",
    "\n",
    "            when(col(\"value_json.op\").isin(\"c\", \"u\", \"r\"), col(\"value_json.after.quantity\"))\n",
    "              .otherwise(lit(None)).alias(\"quantity\"),\n",
    "\n",
    "            when(col(\"value_json.op\").isin(\"c\", \"u\", \"r\"), col(\"value_json.after.order_time\"))\n",
    "              .otherwise(lit(None)).alias(\"order_time\"),\n",
    "\n",
    "            # Version & delete flag\n",
    "            col(\"value_json.ts_ms\").alias(\"_version\"),\n",
    "            when(col(\"value_json.op\") == \"d\", lit(1)).otherwise(lit(0)).alias(\"_deleted\")\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c03ff540-cb8e-4a42-a176-f38e1248a45e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------+----------+--------+----------------+-------------+--------+\n",
      "| id|customer_id|product_id|quantity|      order_time|     _version|_deleted|\n",
      "+---+-----------+----------+--------+----------------+-------------+--------+\n",
      "|  1|          5|        77|       2|1755331695560122|1755593845773|       0|\n",
      "|  2|          5|        31|       4|1755331741489021|1755593845773|       0|\n",
      "|  3|          6|        75|       1|1755331741493392|1755593845774|       0|\n",
      "|  4|          2|        73|       2|1755331741497550|1755593845774|       0|\n",
      "|  5|          4|        48|       2|1755331741501933|1755593845774|       0|\n",
      "|  6|          8|       100|       4|1755331741506137|1755593845775|       0|\n",
      "|  7|          1|         7|       4|1755331741510234|1755593845775|       0|\n",
      "|  8|         10|        17|       2|1755331741514410|1755593845775|       0|\n",
      "|  9|          7|        90|       3|1755331741518874|1755593845776|       0|\n",
      "| 10|          9|        64|       5|1755331741522757|1755593845776|       0|\n",
      "| 11|          9|        47|       1|1755331759687883|1755593845776|       0|\n",
      "| 12|          1|        37|       3|1755331759824266|1755593845776|       0|\n",
      "| 13|          5|        89|       3|1755331759827922|1755593845777|       0|\n",
      "| 14|          7|        91|       3|1755331759830508|1755593845777|       0|\n",
      "| 15|         11|        78|       2|1755331759832792|1755593845777|       0|\n",
      "| 16|          4|        29|       1|1755331759835785|1755593845777|       0|\n",
      "| 17|         11|        70|       1|1755331759839474|1755593845777|       0|\n",
      "| 18|         10|        74|       2|1755331759842838|1755593845778|       0|\n",
      "| 19|         12|        40|       5|1755331759845027|1755593845778|       0|\n",
      "| 20|          2|         8|       5|1755331759847657|1755593845778|       0|\n",
      "+---+-----------+----------+--------+----------------+-------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cdc_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d92edc-fa5e-4bb2-aa23-fe6a8e091794",
   "metadata": {},
   "source": [
    "## Write to Clickhouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1bffc884-438f-417a-81ea-e526991b0149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'user': 'default', 'password': 'clickhouse123', 'driver': 'com.clickhouse.jdbc.ClickHouseDriver'}\n"
     ]
    }
   ],
   "source": [
    "# ClickHouse connection properties\n",
    "clickhouse_properties = app_config.clickhouse.connection_properties\n",
    "print(clickhouse_properties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ec3bc50b-9162-4b5d-82df-7e1835848dfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Writing to console for debugging:\n",
      "+---+-----------+----------+--------+----------------+-------------+--------+\n",
      "|id |customer_id|product_id|quantity|order_time      |_version     |_deleted|\n",
      "+---+-----------+----------+--------+----------------+-------------+--------+\n",
      "|1  |5          |77        |2       |1755331695560122|1755593845773|0       |\n",
      "|2  |5          |31        |4       |1755331741489021|1755593845773|0       |\n",
      "|3  |6          |75        |1       |1755331741493392|1755593845774|0       |\n",
      "|4  |2          |73        |2       |1755331741497550|1755593845774|0       |\n",
      "|5  |4          |48        |2       |1755331741501933|1755593845774|0       |\n",
      "|6  |8          |100       |4       |1755331741506137|1755593845775|0       |\n",
      "|7  |1          |7         |4       |1755331741510234|1755593845775|0       |\n",
      "|8  |10         |17        |2       |1755331741514410|1755593845775|0       |\n",
      "|9  |7          |90        |3       |1755331741518874|1755593845776|0       |\n",
      "|10 |9          |64        |5       |1755331741522757|1755593845776|0       |\n",
      "|11 |9          |47        |1       |1755331759687883|1755593845776|0       |\n",
      "|12 |1          |37        |3       |1755331759824266|1755593845776|0       |\n",
      "|13 |5          |89        |3       |1755331759827922|1755593845777|0       |\n",
      "|14 |7          |91        |3       |1755331759830508|1755593845777|0       |\n",
      "|15 |11         |78        |2       |1755331759832792|1755593845777|0       |\n",
      "|16 |4          |29        |1       |1755331759835785|1755593845777|0       |\n",
      "|17 |11         |70        |1       |1755331759839474|1755593845777|0       |\n",
      "|18 |10         |74        |2       |1755331759842838|1755593845778|0       |\n",
      "|19 |12         |40        |5       |1755331759845027|1755593845778|0       |\n",
      "|20 |2          |8         |5       |1755331759847657|1755593845778|0       |\n",
      "+---+-----------+----------+--------+----------------+-------------+--------+\n",
      "only showing top 20 rows\n",
      "\n",
      "\n",
      "💾 Writing to ClickHouse...\n",
      "✅ Data written to ClickHouse successfully!\n"
     ]
    }
   ],
   "source": [
    "# --- Write to Console (for debugging) ---\n",
    "print(\"\\n📊 Writing to console for debugging:\")\n",
    "cdc_df.show(20, truncate=False)\n",
    "\n",
    "# --- Write to ClickHouse ---\n",
    "try:\n",
    "    print(\"\\n💾 Writing to ClickHouse...\")\n",
    "    \n",
    "    # Write to ClickHouse table (ReplacingMergeTree with _version)\n",
    "    (cdc_df\n",
    "     .write\n",
    "     .format(\"jdbc\")\n",
    "     .option(\"url\", app_config.clickhouse.jdbc_url)\n",
    "     .option(\"dbtable\", \"orders_cdc\")  # Table name in ClickHouse\n",
    "     .option(\"user\", clickhouse_properties['user'])\n",
    "     .option(\"password\", clickhouse_properties['password'])\n",
    "     .option(\"driver\", clickhouse_properties['driver'])\n",
    "     .mode(\"append\")  # Always append for CDC\n",
    "     .save()\n",
    "    )\n",
    "    \n",
    "    print(\"✅ Data written to ClickHouse successfully!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Error writing to ClickHouse: {e}\")\n",
    "    print(\"📝 Writing to console only...\")\n",
    "    cdc_df.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
